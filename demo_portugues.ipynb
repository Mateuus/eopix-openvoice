{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clonagem de Voz em Portugu√™s\n",
    "\n",
    "Este notebook demonstra como gerar voz clonada em portugu√™s usando OpenVoice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diret√≥rio atual: /home/mateuus/projects/eopix/openvoice-server\n",
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Garantir que estamos no diret√≥rio correto\n",
    "expected_dir = '/home/mateuus/projects/eopix/openvoice-server'\n",
    "if os.getcwd() != expected_dir:\n",
    "    print(f\"Mudando diret√≥rio de {os.getcwd()} para {expected_dir}\")\n",
    "    os.chdir(expected_dir)\n",
    "print(f\"Diret√≥rio atual: {os.getcwd()}\")\n",
    "\n",
    "import torch\n",
    "from openvoice import se_extractor\n",
    "from openvoice.api import ToneColorConverter\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar vari√°veis de ambiente\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configura√ß√£o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Output directory: outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateuus/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'checkpoints/converter/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n",
      "‚úì Conversor carregado com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes\n",
    "ckpt_converter = 'checkpoints/converter'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "output_dir = 'outputs'\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Carregar o conversor de cor de tom\n",
    "tone_color_converter = ToneColorConverter(\n",
    "    f'{ckpt_converter}/config.json', \n",
    "    device=device\n",
    ")\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"‚úì Conversor carregado com sucesso\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abordagem para Portugu√™s\n",
    "\n",
    "Para gerar voz em portugu√™s com OpenVoice, usamos **OpenAI TTS** como base speaker.\n",
    "\n",
    "O OpenVoice funciona assim:\n",
    "1. Gera o √°udio com um base speaker (pode ser em qualquer idioma)\n",
    "2. Aplica a cor de tom (timbre) da voz de refer√™ncia\n",
    "\n",
    "Para portugu√™s, usamos:\n",
    "- **Base speaker**: OpenAI TTS em portugu√™s\n",
    "- **Cor de tom**: Qualquer voz de refer√™ncia que voc√™ quiser clonar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gerar base speaker usando OpenAI TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando √°udio base em portugu√™s: Ol√°, este √© um teste de clonagem de voz em portugu√™s brasileiro.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m texto_base = \u001b[33m\"\u001b[39m\u001b[33mOl√°, este √© um teste de clonagem de voz em portugu√™s brasileiro.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGerando √°udio base em portugu√™s: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtexto_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspeech\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtts-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnova\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtexto_base\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m base_speaker_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/base_pt.wav\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m response.stream_to_file(base_speaker_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/openai/resources/audio/speech.py:103\u001b[39m, in \u001b[36mSpeech.create\u001b[39m\u001b[34m(self, input, model, voice, instructions, response_format, speed, stream_format, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03mGenerates audio from the input text.\u001b[39;00m\n\u001b[32m     69\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m extra_headers = {\u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/octet-stream\u001b[39m\u001b[33m\"\u001b[39m, **(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/audio/speech\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvoice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspeed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspeech_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSpeechCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_legacy_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHttpxBinaryResponseContent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Gerar um √°udio em portugu√™s usando OpenAI TTS\n",
    "# IMPORTANTE: O √°udio precisa ter pelo menos 1 segundo para o VAD funcionar\n",
    "texto_base = \"Ol√°, este √© um teste de clonagem de voz em portugu√™s brasileiro. \" \\\n",
    "             \"Este √°udio ser√° usado como base speaker para gerar clonagem de voz. \" \\\n",
    "             \"O OpenVoice √© capaz de replicar a cor tonal de qualquer voz de refer√™ncia \" \\\n",
    "             \"enquanto mant√©m as caracter√≠sticas lingu√≠sticas do base speaker.\"\n",
    "print(f\"Gerando √°udio base em portugu√™s...\")\n",
    "print(f\"Texto: {texto_base[:50]}...\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"nova\",\n",
    "    input=texto_base\n",
    ")\n",
    "\n",
    "base_speaker_path = f\"{output_dir}/base_pt.wav\"\n",
    "response.stream_to_file(base_speaker_path)\n",
    "print(f\"‚úì Base speaker gerado: {base_speaker_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extrair embeddings de cor de tom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair embedding do base speaker (√°udio gerado pelo OpenAI TTS)\n",
    "print(\"Extraindo embedding do base speaker...\")\n",
    "try:\n",
    "    source_se, audio_name = se_extractor.get_se(\n",
    "        base_speaker_path, \n",
    "        tone_color_converter, \n",
    "        vad=True\n",
    "    )\n",
    "    print(f\"‚úì Source SE extra√≠do: {audio_name}\")\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ö†Ô∏è √Åudio muito curto para VAD. Tentando sem VAD...\")\n",
    "    source_se, audio_name = se_extractor.get_se(\n",
    "        base_speaker_path, \n",
    "        tone_color_converter, \n",
    "        vad=False\n",
    "    )\n",
    "    print(f\"‚úì Source SE extra√≠do sem VAD: {audio_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair embedding da voz de refer√™ncia\n",
    "# Use um arquivo de √°udio de 3-10 segundos com a voz que voc√™ quer clonar\n",
    "reference_speaker = 'resources/example_reference.mp3'  # Troque pelo seu arquivo\n",
    "\n",
    "print(f\"Extraindo embedding da voz de refer√™ncia: {reference_speaker}\")\n",
    "try:\n",
    "    target_se, audio_name = se_extractor.get_se(\n",
    "        reference_speaker, \n",
    "        tone_color_converter, \n",
    "        vad=True\n",
    "    )\n",
    "    print(f\"‚úì Target SE extra√≠do: {audio_name}\")\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ö†Ô∏è √Åudio de refer√™ncia muito curto. Tentando sem VAD...\")\n",
    "    target_se, audio_name = se_extractor.get_se(\n",
    "        reference_speaker, \n",
    "        tone_color_converter, \n",
    "        vad=False\n",
    "    )\n",
    "    print(f\"‚úì Target SE extra√≠do sem VAD: {audio_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gerar voz clonada em portugu√™s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos para gerar em portugu√™s\n",
    "textos_pt = [\n",
    "    \"Ol√°, este √© o OpenVoice, um sistema de clonagem de voz.\",\n",
    "    \"Ele pode replicar a cor tonal de qualquer voz de refer√™ncia.\",\n",
    "    \"√â poss√≠vel gerar fala em m√∫ltiplos idiomas e com diferentes emo√ß√µes.\"\n",
    "]\n",
    "\n",
    "src_path = f'{output_dir}/tmp_pt.wav'\n",
    "\n",
    "for i, texto in enumerate(textos_pt):\n",
    "    print(f\"\\n[{i+1}/{len(textos_pt)}] Processando: {texto}\")\n",
    "    \n",
    "    # 1. Gerar TTS em portugu√™s com OpenAI\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=texto\n",
    "    )\n",
    "    response.stream_to_file(src_path)\n",
    "    \n",
    "    # 2. Aplicar clonagem de voz\n",
    "    save_path = f'{output_dir}/output_pt_{i}.wav'\n",
    "    \n",
    "    encode_message = \"@MyShell\"\n",
    "    tone_color_converter.convert(\n",
    "        audio_src_path=src_path,\n",
    "        src_se=source_se,\n",
    "        tgt_se=target_se,\n",
    "        output_path=save_path,\n",
    "        message=encode_message\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Arquivo gerado: {save_path}\")\n",
    "\n",
    "print(\"\\nüéâ Todos os arquivos foram gerados com sucesso!\")\n",
    "print(f\"üìÇ Verifique os arquivos em: {output_dir}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Notas Importantes\n",
    "\n",
    "#### ‚ùå Voc√™ N√ÉO precisa criar checkpoints\n",
    "Os arquivos necess√°rios j√° existem:\n",
    "- `checkpoints_v2/base_speakers/ses/en-br.pth` - Portugu√™s Brasileiro\n",
    "- `checkpoints/converter/checkpoint.pth` - Conversor de cor de tom\n",
    "\n",
    "#### ‚úÖ Como funciona a clonagem\n",
    "1. **Base Speaker**: Gera o conte√∫do de fala (texto ‚Üí √°udio)\n",
    "   - Usamos OpenAI TTS para portugu√™s\n",
    "2. **Conversor de Cor de Tom**: Aplica o timbre da voz de refer√™ncia\n",
    "   - Captura a voz de refer√™ncia e aplica no base speaker\n",
    "\n",
    "#### üîß Ajustar para sua voz\n",
    "Troque o arquivo `reference_speaker` pelo seu √°udio:\n",
    "- 3-10 segundos de √°udio\n",
    "- Fala clara e limpa\n",
    "- Qualquer formato (mp3, wav, etc)\n",
    "\n",
    "#### üöÄ Melhorias futuras\n",
    "Para melhor qualidade, instale o MeloTTS:\n",
    "```bash\n",
    "pip install melo-tts\n",
    "```\n",
    "Depois use o arquivo `en-br.pth` conforme demonstrado no `demo_part3.ipynb`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenVoice Server",
   "language": "python",
   "name": "openvoice-server"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
