{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clonagem de Voz em Português\n",
    "\n",
    "Este notebook demonstra como gerar voz clonada em português usando OpenVoice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório atual: /home/mateuus/projects/eopix/openvoice-server\n",
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# Garantir que estamos no diretório correto\n",
    "expected_dir = '/home/mateuus/projects/eopix/openvoice-server'\n",
    "if os.getcwd() != expected_dir:\n",
    "    print(f\"Mudando diretório de {os.getcwd()} para {expected_dir}\")\n",
    "    os.chdir(expected_dir)\n",
    "print(f\"Diretório atual: {os.getcwd()}\")\n",
    "\n",
    "import torch\n",
    "from openvoice import se_extractor\n",
    "from openvoice.api import ToneColorConverter\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Output directory: outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mateuus/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint 'checkpoints/converter/checkpoint.pth'\n",
      "missing/unexpected keys: [] []\n",
      "✓ Conversor carregado com sucesso\n"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "ckpt_converter = 'checkpoints/converter'\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "output_dir = 'outputs'\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Carregar o conversor de cor de tom\n",
    "tone_color_converter = ToneColorConverter(\n",
    "    f'{ckpt_converter}/config.json', \n",
    "    device=device\n",
    ")\n",
    "tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"✓ Conversor carregado com sucesso\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abordagem para Português\n",
    "\n",
    "Para gerar voz em português com OpenVoice, usamos **OpenAI TTS** como base speaker.\n",
    "\n",
    "O OpenVoice funciona assim:\n",
    "1. Gera o áudio com um base speaker (pode ser em qualquer idioma)\n",
    "2. Aplica a cor de tom (timbre) da voz de referência\n",
    "\n",
    "Para português, usamos:\n",
    "- **Base speaker**: OpenAI TTS em português\n",
    "- **Cor de tom**: Qualquer voz de referência que você quiser clonar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gerar base speaker usando OpenAI TTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando áudio base em português: Olá, este é um teste de clonagem de voz em português brasileiro.\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m texto_base = \u001b[33m\"\u001b[39m\u001b[33mOlá, este é um teste de clonagem de voz em português brasileiro.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGerando áudio base em português: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtexto_base\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspeech\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtts-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnova\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mtexto_base\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m base_speaker_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/base_pt.wav\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     15\u001b[39m response.stream_to_file(base_speaker_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/openai/resources/audio/speech.py:103\u001b[39m, in \u001b[36mSpeech.create\u001b[39m\u001b[34m(self, input, model, voice, instructions, response_format, speed, stream_format, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[33;03mGenerates audio from the input text.\u001b[39;00m\n\u001b[32m     69\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \u001b[33;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    101\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m extra_headers = {\u001b[33m\"\u001b[39m\u001b[33mAccept\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/octet-stream\u001b[39m\u001b[33m\"\u001b[39m, **(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/audio/speech\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvoice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mspeed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspeech_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSpeechCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_legacy_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHttpxBinaryResponseContent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/eopix/openvoice-server/venv/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "# Inicializar cliente OpenAI\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Gerar um áudio em português usando OpenAI TTS\n",
    "# IMPORTANTE: O áudio precisa ter pelo menos 1 segundo para o VAD funcionar\n",
    "texto_base = \"Olá, este é um teste de clonagem de voz em português brasileiro. \" \\\n",
    "             \"Este áudio será usado como base speaker para gerar clonagem de voz. \" \\\n",
    "             \"O OpenVoice é capaz de replicar a cor tonal de qualquer voz de referência \" \\\n",
    "             \"enquanto mantém as características linguísticas do base speaker.\"\n",
    "print(f\"Gerando áudio base em português...\")\n",
    "print(f\"Texto: {texto_base[:50]}...\")\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"nova\",\n",
    "    input=texto_base\n",
    ")\n",
    "\n",
    "base_speaker_path = f\"{output_dir}/base_pt.wav\"\n",
    "response.stream_to_file(base_speaker_path)\n",
    "print(f\"✓ Base speaker gerado: {base_speaker_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extrair embeddings de cor de tom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair embedding do base speaker (áudio gerado pelo OpenAI TTS)\n",
    "print(\"Extraindo embedding do base speaker...\")\n",
    "try:\n",
    "    source_se, audio_name = se_extractor.get_se(\n",
    "        base_speaker_path, \n",
    "        tone_color_converter, \n",
    "        vad=True\n",
    "    )\n",
    "    print(f\"✓ Source SE extraído: {audio_name}\")\n",
    "except AssertionError as e:\n",
    "    print(f\"⚠️ Áudio muito curto para VAD. Tentando sem VAD...\")\n",
    "    source_se, audio_name = se_extractor.get_se(\n",
    "        base_speaker_path, \n",
    "        tone_color_converter, \n",
    "        vad=False\n",
    "    )\n",
    "    print(f\"✓ Source SE extraído sem VAD: {audio_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair embedding da voz de referência\n",
    "# Use um arquivo de áudio de 3-10 segundos com a voz que você quer clonar\n",
    "reference_speaker = 'resources/example_reference.mp3'  # Troque pelo seu arquivo\n",
    "\n",
    "print(f\"Extraindo embedding da voz de referência: {reference_speaker}\")\n",
    "try:\n",
    "    target_se, audio_name = se_extractor.get_se(\n",
    "        reference_speaker, \n",
    "        tone_color_converter, \n",
    "        vad=True\n",
    "    )\n",
    "    print(f\"✓ Target SE extraído: {audio_name}\")\n",
    "except AssertionError as e:\n",
    "    print(f\"⚠️ Áudio de referência muito curto. Tentando sem VAD...\")\n",
    "    target_se, audio_name = se_extractor.get_se(\n",
    "        reference_speaker, \n",
    "        tone_color_converter, \n",
    "        vad=False\n",
    "    )\n",
    "    print(f\"✓ Target SE extraído sem VAD: {audio_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gerar voz clonada em português\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textos para gerar em português\n",
    "textos_pt = [\n",
    "    \"Olá, este é o OpenVoice, um sistema de clonagem de voz.\",\n",
    "    \"Ele pode replicar a cor tonal de qualquer voz de referência.\",\n",
    "    \"É possível gerar fala em múltiplos idiomas e com diferentes emoções.\"\n",
    "]\n",
    "\n",
    "src_path = f'{output_dir}/tmp_pt.wav'\n",
    "\n",
    "for i, texto in enumerate(textos_pt):\n",
    "    print(f\"\\n[{i+1}/{len(textos_pt)}] Processando: {texto}\")\n",
    "    \n",
    "    # 1. Gerar TTS em português com OpenAI\n",
    "    response = client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"nova\",\n",
    "        input=texto\n",
    "    )\n",
    "    response.stream_to_file(src_path)\n",
    "    \n",
    "    # 2. Aplicar clonagem de voz\n",
    "    save_path = f'{output_dir}/output_pt_{i}.wav'\n",
    "    \n",
    "    encode_message = \"@MyShell\"\n",
    "    tone_color_converter.convert(\n",
    "        audio_src_path=src_path,\n",
    "        src_se=source_se,\n",
    "        tgt_se=target_se,\n",
    "        output_path=save_path,\n",
    "        message=encode_message\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Arquivo gerado: {save_path}\")\n",
    "\n",
    "print(\"\\n🎉 Todos os arquivos foram gerados com sucesso!\")\n",
    "print(f\"📂 Verifique os arquivos em: {output_dir}/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📝 Notas Importantes\n",
    "\n",
    "#### ❌ Você NÃO precisa criar checkpoints\n",
    "Os arquivos necessários já existem:\n",
    "- `checkpoints_v2/base_speakers/ses/en-br.pth` - Português Brasileiro\n",
    "- `checkpoints/converter/checkpoint.pth` - Conversor de cor de tom\n",
    "\n",
    "#### ✅ Como funciona a clonagem\n",
    "1. **Base Speaker**: Gera o conteúdo de fala (texto → áudio)\n",
    "   - Usamos OpenAI TTS para português\n",
    "2. **Conversor de Cor de Tom**: Aplica o timbre da voz de referência\n",
    "   - Captura a voz de referência e aplica no base speaker\n",
    "\n",
    "#### 🔧 Ajustar para sua voz\n",
    "Troque o arquivo `reference_speaker` pelo seu áudio:\n",
    "- 3-10 segundos de áudio\n",
    "- Fala clara e limpa\n",
    "- Qualquer formato (mp3, wav, etc)\n",
    "\n",
    "#### 🚀 Melhorias futuras\n",
    "Para melhor qualidade, instale o MeloTTS:\n",
    "```bash\n",
    "pip install melo-tts\n",
    "```\n",
    "Depois use o arquivo `en-br.pth` conforme demonstrado no `demo_part3.ipynb`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenVoice Server",
   "language": "python",
   "name": "openvoice-server"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
